{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# For tips on running notebooks in Google Colab, see\n",
        "# https://pytorch.org/tutorials/beginner/colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Neural Networks\n",
        "\n",
        "Neural networks can be constructed using the ``torch.nn`` package.\n",
        "\n",
        "Now that you had a glimpse of ``autograd``, ``nn`` depends on\n",
        "``autograd`` to define models and differentiate them.\n",
        "An ``nn.Module`` contains layers, and a method ``forward(input)`` that\n",
        "returns the ``output``.\n",
        "\n",
        "For example, look at this network that classifies digit images:\n",
        "\n",
        ".. figure:: /_static/img/mnist.png\n",
        "   :alt: convnet\n",
        "\n",
        "   convnet\n",
        "\n",
        "It is a simple feed-forward network. It takes the input, feeds it\n",
        "through several layers one after the other, and then finally gives the\n",
        "output.\n",
        "\n",
        "A typical training procedure for a neural network is as follows:\n",
        "\n",
        "- Define the neural network that has some learnable parameters (or\n",
        "  weights)\n",
        "- Iterate over a dataset of inputs\n",
        "- Process input through the network\n",
        "- Compute the loss (how far is the output from being correct)\n",
        "- Propagate gradients back into the network’s parameters\n",
        "- Update the weights of the network, typically using a simple update rule:\n",
        "  ``weight = weight - learning_rate * gradient``\n",
        "\n",
        "## Define the network\n",
        "\n",
        "Let’s define this network:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
        "        # kernel\n",
        "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        # an affine operation: y = Wx + b\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5 from image dimension \n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square, you can specify with a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except the batch dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "net = Net()\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You just have to define the ``forward`` function, and the ``backward``\n",
        "function (where gradients are computed) is automatically defined for you\n",
        "using ``autograd``.\n",
        "You can use any of the Tensor operations in the ``forward`` function.\n",
        "\n",
        "The learnable parameters of a model are returned by ``net.parameters()``\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n",
            "torch.Size([6, 1, 5, 5])\n",
            "[Parameter containing:\n",
            "tensor([[[[ 0.0784,  0.0107,  0.0768,  0.0184,  0.0329],\n",
            "          [-0.1733, -0.0018, -0.1520,  0.1474,  0.0180],\n",
            "          [ 0.0323, -0.0400, -0.1763,  0.0297, -0.0824],\n",
            "          [ 0.1062,  0.0470,  0.0803,  0.1703, -0.1819],\n",
            "          [-0.0456,  0.1461, -0.1192,  0.0891, -0.0059]]],\n",
            "\n",
            "\n",
            "        [[[-0.1276, -0.0214, -0.0523,  0.0147, -0.0666],\n",
            "          [ 0.1076, -0.0155,  0.1695,  0.1052, -0.0287],\n",
            "          [ 0.0536, -0.1999,  0.1576, -0.1913, -0.1640],\n",
            "          [-0.0926, -0.0081, -0.1567, -0.0966,  0.1108],\n",
            "          [ 0.0934,  0.1392,  0.0639,  0.1294,  0.0723]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1527, -0.0928,  0.1245, -0.0185,  0.1153],\n",
            "          [-0.1796,  0.1900, -0.0755, -0.0519,  0.1240],\n",
            "          [-0.1109, -0.0778,  0.1353,  0.1046,  0.1303],\n",
            "          [-0.1629,  0.1628,  0.0716,  0.1391,  0.0551],\n",
            "          [-0.1208,  0.1541,  0.1369, -0.0282, -0.1895]]],\n",
            "\n",
            "\n",
            "        [[[-0.0412, -0.0168,  0.1298,  0.0471,  0.0533],\n",
            "          [ 0.1279,  0.1502, -0.1628, -0.1311, -0.1648],\n",
            "          [ 0.1948,  0.0226,  0.0635,  0.0929, -0.1165],\n",
            "          [ 0.1044, -0.1996, -0.0467,  0.1060, -0.1392],\n",
            "          [ 0.1588, -0.1392, -0.1221,  0.1086,  0.0195]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1874,  0.1409,  0.0768,  0.0881, -0.1785],\n",
            "          [-0.1095,  0.1244, -0.1650, -0.0471,  0.1242],\n",
            "          [ 0.1988,  0.0476,  0.0893, -0.0712,  0.1390],\n",
            "          [ 0.0933, -0.0024, -0.1331,  0.1791, -0.1492],\n",
            "          [ 0.1408,  0.1252,  0.1470,  0.0606,  0.1039]]],\n",
            "\n",
            "\n",
            "        [[[-0.1429, -0.1631,  0.0492, -0.1923, -0.1518],\n",
            "          [ 0.0532, -0.0639,  0.1970,  0.0921,  0.0366],\n",
            "          [ 0.1792,  0.0470,  0.0562, -0.1363, -0.1484],\n",
            "          [ 0.1693,  0.1555, -0.0322,  0.0118, -0.1135],\n",
            "          [-0.1362, -0.0019,  0.1067,  0.1463, -0.0855]]]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0071,  0.1636, -0.1396,  0.0598,  0.0575, -0.0074],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[[[ 5.3687e-04, -1.5324e-03, -6.3048e-02,  4.4260e-02,  2.9508e-02],\n",
            "          [ 3.0000e-02,  2.6929e-02, -4.1968e-02,  3.9959e-02, -4.8976e-02],\n",
            "          [-2.6410e-02, -2.2960e-02, -6.6207e-02,  4.7405e-02, -7.5256e-02],\n",
            "          [ 2.4935e-02,  7.1929e-02, -7.7056e-02,  6.4198e-02,  6.3936e-02],\n",
            "          [ 1.6281e-02, -4.8950e-02,  2.3802e-02, -4.0586e-02, -2.2544e-03]],\n",
            "\n",
            "         [[ 5.1515e-02, -7.2910e-02,  1.8984e-02, -3.4758e-03, -4.2204e-02],\n",
            "          [ 9.0241e-03,  3.0119e-02,  4.3065e-02, -3.9077e-02, -5.5063e-02],\n",
            "          [-4.6582e-02,  1.2258e-04,  6.0554e-02, -2.8603e-02,  4.4110e-02],\n",
            "          [-5.9860e-02, -3.4340e-02,  5.5439e-02,  3.6737e-02,  7.2433e-02],\n",
            "          [-6.7199e-02,  2.7428e-02,  3.5889e-02, -3.0676e-02,  1.3763e-02]],\n",
            "\n",
            "         [[ 3.8828e-02,  5.6039e-02,  3.9725e-02, -7.7973e-03,  3.8513e-02],\n",
            "          [ 3.5614e-03, -6.5060e-02, -7.7153e-02,  2.1792e-02,  8.0371e-02],\n",
            "          [-4.4783e-03,  1.1083e-02,  2.5138e-05,  5.6549e-02,  8.1097e-02],\n",
            "          [-4.4776e-02, -6.5871e-02,  7.0170e-02, -6.2679e-02, -3.3109e-02],\n",
            "          [ 5.7741e-02,  1.9131e-02, -3.8013e-02,  7.3090e-02,  3.3287e-02]],\n",
            "\n",
            "         [[ 7.8641e-03, -5.0921e-02, -4.2716e-02, -1.7367e-02,  3.5865e-02],\n",
            "          [-7.4312e-02,  6.3402e-02,  6.9697e-02, -6.6749e-02,  8.9593e-03],\n",
            "          [ 2.5368e-02,  7.3567e-02, -5.1484e-02,  3.1098e-02,  2.6670e-02],\n",
            "          [ 3.8597e-02,  8.1288e-02,  1.9169e-02, -6.5063e-02, -7.6699e-02],\n",
            "          [-1.4426e-02, -3.7648e-02,  2.3299e-02,  7.3145e-03,  2.2747e-02]],\n",
            "\n",
            "         [[-3.3613e-02,  2.4392e-02,  4.0485e-02,  1.1587e-02,  5.5123e-02],\n",
            "          [-4.1688e-02,  9.4399e-03,  2.0271e-02,  3.5349e-02, -3.6882e-02],\n",
            "          [-6.0815e-02,  1.8502e-02, -6.9341e-03, -1.0916e-02, -5.1503e-03],\n",
            "          [ 3.1004e-02, -1.8023e-02,  3.8749e-02,  5.9404e-02, -2.5178e-02],\n",
            "          [ 1.7600e-02, -2.5527e-02,  3.2927e-02, -2.6291e-02,  3.7601e-04]],\n",
            "\n",
            "         [[ 5.5580e-02,  8.9460e-03,  5.7293e-04,  2.5985e-02,  5.7809e-02],\n",
            "          [-2.7711e-02,  5.6435e-02,  4.2458e-02, -1.9820e-02, -7.0326e-02],\n",
            "          [ 1.9785e-02,  5.6409e-02,  3.0124e-02, -6.7820e-02,  4.9467e-02],\n",
            "          [-7.5454e-03, -3.8729e-02,  3.2947e-02, -4.9500e-03, -7.8568e-02],\n",
            "          [-5.0805e-02,  6.2292e-02,  8.0713e-02,  5.3709e-02, -6.7743e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7898e-02,  4.3421e-02, -8.1362e-02, -5.0712e-02,  6.2787e-02],\n",
            "          [ 4.8974e-02,  1.5086e-02,  1.3619e-02,  2.0601e-02, -2.3092e-02],\n",
            "          [-7.2671e-02, -2.1006e-03, -3.6266e-02,  3.8097e-02,  6.7524e-02],\n",
            "          [ 2.3854e-02, -1.3436e-02,  6.7728e-02, -8.4134e-03, -6.6352e-02],\n",
            "          [-1.7312e-02,  5.2278e-02,  6.8334e-02,  2.9849e-02,  6.8568e-02]],\n",
            "\n",
            "         [[ 7.2592e-02,  4.0056e-02,  4.5145e-02, -2.1814e-02,  3.8815e-02],\n",
            "          [-7.8147e-02,  6.8883e-02, -7.9062e-02, -4.0729e-02, -3.5591e-02],\n",
            "          [-7.4694e-02,  3.5508e-02, -2.2567e-02,  2.3516e-02, -5.3777e-03],\n",
            "          [-2.1274e-02,  7.1121e-02,  6.8486e-05,  2.4252e-03, -2.9078e-02],\n",
            "          [ 6.9996e-02, -2.4750e-02,  2.4878e-02, -5.3890e-02,  5.5831e-02]],\n",
            "\n",
            "         [[-1.6319e-02, -3.8118e-03,  7.6365e-02, -1.9013e-02, -5.4895e-02],\n",
            "          [ 6.2475e-03,  6.9519e-03,  4.7085e-02,  7.4192e-02,  6.1340e-02],\n",
            "          [ 2.8524e-02,  2.6014e-02, -6.5529e-02,  6.9918e-02,  2.1438e-03],\n",
            "          [-4.8784e-02, -2.5615e-02,  6.3410e-03, -8.0291e-02,  7.0164e-02],\n",
            "          [ 4.9999e-03,  5.8468e-02, -5.2658e-03, -5.4186e-02,  6.1796e-02]],\n",
            "\n",
            "         [[ 2.7825e-02, -1.4581e-02,  3.2179e-02, -5.2126e-03, -1.0777e-02],\n",
            "          [ 9.2459e-03, -7.3523e-02,  7.6166e-02, -3.1733e-02, -4.8167e-02],\n",
            "          [-1.7657e-02, -7.7506e-03, -1.7111e-02,  3.3671e-03, -7.5045e-02],\n",
            "          [-4.8679e-02, -3.1304e-02, -1.6659e-02, -9.5223e-03,  5.4352e-02],\n",
            "          [ 7.6604e-02, -4.2955e-02,  1.4036e-02, -5.1958e-02,  2.4613e-02]],\n",
            "\n",
            "         [[-2.2134e-02, -5.4779e-02, -6.8837e-03,  6.0558e-03, -6.9496e-02],\n",
            "          [ 4.1942e-02, -1.6729e-02,  7.4278e-02,  3.5523e-02, -6.6740e-02],\n",
            "          [ 8.0438e-02, -4.7762e-03,  2.9075e-02,  3.5282e-02,  3.7979e-02],\n",
            "          [ 2.5300e-02, -7.3810e-02, -2.0620e-02, -5.6666e-02, -2.5289e-02],\n",
            "          [ 4.5398e-02,  7.3287e-02, -7.9663e-02, -1.3282e-02, -5.1432e-02]],\n",
            "\n",
            "         [[ 1.8414e-02, -7.1904e-02, -6.4223e-02, -5.1665e-02,  1.8067e-02],\n",
            "          [ 5.9469e-02,  5.7952e-02, -7.3134e-02, -5.6035e-02, -7.7960e-02],\n",
            "          [-4.0044e-02, -3.8077e-02, -7.6686e-03, -7.2943e-02,  5.0733e-02],\n",
            "          [ 2.4695e-02,  4.3627e-02, -7.6725e-02,  7.1799e-03, -7.5246e-02],\n",
            "          [-1.5035e-02,  4.2631e-02,  4.8669e-02,  6.8366e-03, -8.1130e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8432e-02, -9.3369e-03,  6.5368e-02,  1.3987e-02,  7.8182e-02],\n",
            "          [ 6.6144e-02, -6.3477e-02, -1.8032e-02,  2.5708e-02,  1.6237e-02],\n",
            "          [-1.5261e-02, -1.5466e-03,  7.7048e-02, -3.4800e-02,  3.6723e-02],\n",
            "          [-4.7715e-02, -4.7273e-02,  6.8507e-02, -6.8349e-03,  7.7740e-02],\n",
            "          [ 2.6148e-02, -3.9360e-03, -6.4649e-02, -5.3109e-02,  7.4999e-02]],\n",
            "\n",
            "         [[ 5.1968e-02, -5.2910e-02,  2.0191e-03, -4.4224e-02, -9.7997e-03],\n",
            "          [ 7.2011e-02,  3.6804e-02,  3.3198e-02,  4.0164e-02,  6.5232e-02],\n",
            "          [ 8.0944e-02,  9.5038e-03, -3.7291e-03, -1.0667e-02, -6.1051e-02],\n",
            "          [ 6.9010e-02, -5.7317e-02, -7.6861e-02,  4.9122e-03, -5.9920e-02],\n",
            "          [-5.7373e-02, -6.1788e-03,  8.8296e-03, -4.0045e-02, -5.8421e-02]],\n",
            "\n",
            "         [[ 7.5143e-02, -7.7661e-03,  3.4560e-02,  5.1973e-02,  1.9047e-02],\n",
            "          [ 2.0549e-02,  5.4997e-02, -6.3045e-02,  3.2337e-02, -2.9041e-02],\n",
            "          [ 2.1991e-02,  3.9331e-02, -2.9322e-02,  6.5265e-02,  7.3403e-02],\n",
            "          [-4.2317e-02,  1.8335e-02,  8.0535e-02,  7.3509e-02, -8.4421e-03],\n",
            "          [ 5.9111e-02,  1.8595e-02,  3.5472e-02,  8.0192e-02,  7.6353e-02]],\n",
            "\n",
            "         [[-3.1703e-02, -6.6318e-02, -5.8162e-02, -7.5828e-03,  7.1801e-02],\n",
            "          [ 2.5427e-02,  5.4215e-02, -1.6031e-03,  1.7518e-03, -5.2267e-02],\n",
            "          [ 4.4379e-02, -2.7943e-02,  2.1223e-02,  7.9759e-02, -8.0215e-02],\n",
            "          [ 8.1130e-02, -2.5026e-02,  6.0440e-03, -2.1361e-02, -1.2093e-04],\n",
            "          [ 2.7666e-02,  4.5919e-02,  4.5010e-02,  7.7232e-02, -4.8151e-02]],\n",
            "\n",
            "         [[-6.2469e-02, -3.1276e-02,  6.2823e-02, -4.8146e-03, -3.2381e-03],\n",
            "          [ 9.9965e-03, -2.4967e-02, -4.4192e-02, -3.1661e-02,  7.9322e-02],\n",
            "          [ 2.5282e-02,  1.8098e-02,  1.6487e-02, -6.6394e-02, -7.3184e-02],\n",
            "          [ 4.8603e-02,  1.0518e-02,  6.7480e-02, -5.4954e-02,  4.1915e-02],\n",
            "          [ 3.4231e-02, -8.4611e-03, -7.4618e-02, -2.4173e-02, -6.3407e-02]],\n",
            "\n",
            "         [[-1.5784e-02, -3.3968e-02,  1.4744e-03,  4.1238e-02,  8.1019e-02],\n",
            "          [-1.8166e-02, -6.4828e-02,  3.9582e-02, -5.4733e-02,  7.0753e-02],\n",
            "          [-7.1489e-02, -4.1249e-03, -8.1389e-02, -7.3471e-02, -1.3790e-02],\n",
            "          [-1.3948e-02,  7.5071e-02, -5.1027e-02, -6.7335e-02,  5.2523e-02],\n",
            "          [-4.4672e-02, -3.7475e-02,  3.8479e-03,  2.7430e-02,  4.9982e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.8088e-02,  6.5442e-02,  2.1922e-02, -4.8822e-03,  5.3449e-02],\n",
            "          [-2.4194e-02, -2.2733e-02, -5.1735e-02, -6.0200e-02,  7.7575e-02],\n",
            "          [-1.4548e-03, -3.4750e-02,  4.3871e-02,  8.0148e-02,  7.4729e-02],\n",
            "          [ 5.9534e-02, -3.8611e-03, -3.5377e-02, -6.9545e-02, -1.1090e-02],\n",
            "          [-2.7008e-02,  2.0017e-02, -2.3816e-02,  8.0909e-02,  4.7625e-02]],\n",
            "\n",
            "         [[ 3.2659e-02,  5.2740e-03,  7.4056e-02,  5.9251e-02,  6.5506e-03],\n",
            "          [-6.8699e-02, -4.2468e-02,  2.1724e-02,  1.6665e-02, -5.3036e-02],\n",
            "          [ 6.0380e-02,  2.4946e-02,  3.9993e-02,  8.0421e-02,  3.6264e-02],\n",
            "          [ 1.0059e-02,  4.0408e-02, -7.8814e-02, -3.1937e-02, -4.4044e-02],\n",
            "          [ 1.6771e-02, -7.2625e-03,  3.1791e-02, -2.8947e-02,  4.1777e-02]],\n",
            "\n",
            "         [[-4.9745e-03, -4.4703e-02, -6.6762e-02,  9.8427e-03,  4.4000e-02],\n",
            "          [ 4.6941e-02,  4.7967e-02, -2.8652e-03, -2.0928e-02, -3.3337e-02],\n",
            "          [-9.1677e-03, -1.0026e-03,  2.9267e-02, -6.8337e-02, -4.8512e-02],\n",
            "          [-7.1731e-02,  3.5307e-02,  3.5727e-02,  2.1616e-02, -1.5726e-02],\n",
            "          [ 2.6604e-02, -3.1601e-02,  5.2534e-02,  3.1807e-02,  2.5148e-03]],\n",
            "\n",
            "         [[-6.5696e-02, -8.9896e-04, -1.0480e-03, -2.7204e-02, -2.5463e-02],\n",
            "          [ 2.4759e-02, -7.0192e-02, -6.9374e-02, -2.8595e-02,  4.6839e-02],\n",
            "          [-3.0548e-03, -5.9617e-02, -8.1428e-02,  3.1995e-02, -6.7876e-02],\n",
            "          [-5.5668e-02, -4.6710e-04, -3.2327e-02,  3.5188e-03, -2.7199e-03],\n",
            "          [ 7.5690e-02, -4.5878e-02, -1.6244e-02, -1.0797e-02,  2.6812e-03]],\n",
            "\n",
            "         [[-7.7886e-02, -1.8388e-02,  5.0172e-02,  7.8459e-02,  1.6611e-02],\n",
            "          [-4.6467e-02,  8.2398e-03, -4.3963e-02,  6.1998e-03, -5.8738e-02],\n",
            "          [-4.3149e-02,  7.2086e-02,  1.9555e-02, -8.8796e-05, -5.5862e-02],\n",
            "          [ 5.0089e-03, -4.7395e-02,  3.3512e-03,  7.4224e-02,  5.5884e-02],\n",
            "          [ 2.6969e-02,  2.7616e-02,  7.7578e-04, -7.9798e-02, -5.6761e-02]],\n",
            "\n",
            "         [[-5.1014e-03, -2.5308e-02, -6.8865e-02,  1.4969e-02, -1.8625e-02],\n",
            "          [-6.2506e-02, -1.2869e-02, -7.4609e-02, -2.3644e-02, -4.0086e-02],\n",
            "          [-1.7602e-02,  1.3560e-02,  1.0671e-02, -3.7102e-02,  5.1241e-02],\n",
            "          [ 6.0027e-02, -2.9141e-02,  2.0717e-02, -7.3721e-03, -5.6024e-02],\n",
            "          [ 3.6096e-02,  2.0617e-02, -4.9779e-02,  7.0322e-02, -5.8098e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2528e-02, -6.0681e-02, -5.2332e-02, -7.5629e-04, -4.6607e-02],\n",
            "          [ 7.5983e-02,  8.8838e-03,  1.4968e-02,  4.5910e-02, -2.2308e-02],\n",
            "          [-5.8298e-02,  4.7052e-02, -5.1487e-02,  4.8846e-02,  6.2121e-02],\n",
            "          [-3.7541e-02, -6.8125e-02,  7.5321e-02,  3.3625e-02, -6.7508e-02],\n",
            "          [ 5.3728e-02, -6.7791e-02, -8.1142e-02,  5.1347e-02,  7.2379e-02]],\n",
            "\n",
            "         [[-7.3323e-02,  2.6916e-02,  6.5303e-02, -2.3201e-02,  7.4166e-02],\n",
            "          [ 1.7448e-02, -1.5155e-02,  3.1904e-02, -5.9456e-02, -7.4775e-02],\n",
            "          [-4.0403e-02, -3.8360e-02,  1.0079e-02,  7.1212e-02, -4.7669e-02],\n",
            "          [ 3.3548e-02,  2.9910e-02, -1.6942e-03,  5.7577e-02,  3.7178e-06],\n",
            "          [-6.0140e-02, -1.6603e-02, -7.1385e-02,  2.3045e-02, -7.6107e-02]],\n",
            "\n",
            "         [[-1.4477e-02, -5.6123e-02,  5.8949e-02,  2.8771e-02,  2.0913e-02],\n",
            "          [ 2.4791e-02, -6.9973e-02, -3.6953e-03,  3.4626e-02, -5.8729e-02],\n",
            "          [ 6.8759e-02,  7.9057e-02, -5.3359e-02, -4.3227e-02,  1.8759e-02],\n",
            "          [-2.1033e-02, -4.6532e-02,  5.5112e-02,  7.1193e-02, -4.4977e-02],\n",
            "          [ 7.0795e-02, -4.8763e-02,  5.2102e-02,  5.9966e-02, -6.5081e-02]],\n",
            "\n",
            "         [[-6.2534e-02, -4.0409e-02, -6.6293e-02,  4.8943e-02, -6.1736e-03],\n",
            "          [-5.4675e-02,  4.3814e-02,  2.5523e-02,  1.6328e-02, -2.3810e-04],\n",
            "          [-3.7718e-02, -3.8390e-02,  9.0840e-03, -7.2898e-02, -4.0237e-02],\n",
            "          [-2.6762e-03, -7.9038e-03, -6.0049e-02, -3.4552e-02,  8.1646e-02],\n",
            "          [-4.0772e-02, -2.3474e-02, -3.0599e-02, -7.5680e-02,  1.9711e-02]],\n",
            "\n",
            "         [[ 3.7379e-02,  6.4363e-02,  2.5024e-02,  5.7908e-02,  6.6105e-02],\n",
            "          [ 1.2238e-02,  3.4963e-02, -7.0029e-02, -1.1729e-02, -4.9690e-02],\n",
            "          [ 5.7619e-02,  6.1076e-02,  1.2198e-02,  3.4953e-02,  3.7002e-02],\n",
            "          [ 5.9871e-02,  2.2298e-02,  5.5566e-02,  6.2906e-02, -1.3670e-03],\n",
            "          [-2.9419e-02, -4.9888e-02,  4.2023e-02, -7.2474e-02, -7.4519e-02]],\n",
            "\n",
            "         [[ 2.8740e-02, -3.3294e-02, -1.1927e-02, -7.2661e-02, -4.8765e-02],\n",
            "          [-5.4312e-03, -1.3812e-02,  3.8858e-03,  5.6917e-02,  2.8096e-02],\n",
            "          [ 5.7241e-02, -6.5919e-02, -2.8929e-03,  3.3453e-03, -2.8175e-02],\n",
            "          [ 1.1199e-02,  4.9235e-03,  1.2710e-02, -6.7430e-02, -4.3371e-02],\n",
            "          [ 2.3220e-02, -5.5280e-02,  1.7977e-02,  1.8026e-02, -4.7994e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7941e-02, -1.9548e-02,  1.1079e-02,  1.3518e-03,  3.1834e-02],\n",
            "          [ 5.1981e-02, -5.1975e-02,  3.3703e-02,  5.1032e-02, -5.0417e-02],\n",
            "          [ 4.7545e-02,  3.8763e-02,  6.7746e-02, -5.2574e-02, -2.4158e-02],\n",
            "          [-2.0074e-02,  3.4534e-02, -3.3943e-02,  3.4062e-03, -5.0988e-03],\n",
            "          [ 5.6897e-03, -5.5322e-02,  2.7370e-02,  1.7562e-02, -4.6050e-02]],\n",
            "\n",
            "         [[-5.3320e-03, -7.1789e-02, -6.1708e-02, -1.5073e-03, -2.0824e-02],\n",
            "          [-1.3757e-02,  4.2277e-02, -3.2192e-02, -7.6239e-02, -2.9762e-02],\n",
            "          [ 6.8784e-02,  6.7591e-02,  4.2945e-02, -7.4748e-02, -6.9396e-02],\n",
            "          [ 3.6625e-02, -3.1947e-02, -1.0144e-02, -1.9491e-02,  6.2802e-02],\n",
            "          [-1.7211e-02, -3.8433e-02,  2.9557e-02,  1.8989e-02,  7.2054e-02]],\n",
            "\n",
            "         [[-3.4068e-03, -7.0179e-02,  3.6047e-02, -6.5481e-02,  6.0805e-02],\n",
            "          [ 3.7167e-02, -8.1333e-02, -4.5995e-02,  5.6917e-02, -7.2487e-02],\n",
            "          [-6.9461e-02, -6.2403e-02,  5.4280e-02, -3.6052e-02, -3.5709e-02],\n",
            "          [ 6.6073e-02,  4.5609e-02,  7.2912e-02,  4.1374e-02,  7.1956e-02],\n",
            "          [ 2.8976e-02,  7.0588e-02,  6.7817e-02,  1.4612e-02, -5.7426e-02]],\n",
            "\n",
            "         [[ 4.6968e-02,  1.0870e-02,  3.1188e-02,  3.2739e-02, -7.5199e-02],\n",
            "          [-6.4615e-03, -1.8443e-02,  4.9752e-02,  2.9344e-02, -1.8397e-02],\n",
            "          [-7.4586e-02, -6.3929e-02, -1.8614e-02, -5.6958e-02,  4.1573e-02],\n",
            "          [ 2.0473e-02,  5.5966e-02,  1.7198e-02, -8.2711e-03, -3.2941e-02],\n",
            "          [-5.9660e-02, -7.3290e-02, -1.4778e-02,  5.9301e-02, -5.2163e-02]],\n",
            "\n",
            "         [[ 7.8621e-02,  5.4868e-02, -5.7367e-02,  5.1352e-02,  5.2558e-02],\n",
            "          [-3.9672e-02,  2.3736e-02,  4.6950e-02,  5.4699e-02, -8.1267e-03],\n",
            "          [-5.2622e-02,  5.8935e-02, -1.2731e-02,  3.2615e-02, -6.2654e-02],\n",
            "          [ 4.0638e-02, -9.5615e-03, -1.2419e-02, -3.1775e-02,  3.7953e-02],\n",
            "          [-1.0690e-02, -3.7562e-02,  1.4093e-02,  1.5276e-02, -1.3388e-02]],\n",
            "\n",
            "         [[ 7.7236e-02, -2.8992e-02,  2.6879e-02,  4.4949e-02, -7.8924e-02],\n",
            "          [-5.9972e-02, -4.5836e-02, -8.0267e-02,  1.5504e-02,  1.4627e-03],\n",
            "          [ 7.3731e-02, -4.2028e-02,  7.8252e-02, -6.0823e-02,  7.5155e-02],\n",
            "          [ 7.6481e-02, -1.7176e-02,  1.1887e-02,  3.0791e-02,  1.1297e-02],\n",
            "          [-6.2576e-02,  3.0804e-02, -2.2428e-02,  2.4679e-02, -3.2517e-02]]]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0453, -0.0541, -0.0409,  0.0203,  0.0757, -0.0726,  0.0668,  0.0735,\n",
            "         0.0372,  0.0345, -0.0060,  0.0077,  0.0794,  0.0670, -0.0560, -0.0593],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0329,  0.0121, -0.0407,  ...,  0.0347, -0.0359, -0.0220],\n",
            "        [-0.0270,  0.0231, -0.0448,  ..., -0.0469,  0.0067, -0.0133],\n",
            "        [-0.0366,  0.0136,  0.0086,  ..., -0.0086,  0.0012, -0.0388],\n",
            "        ...,\n",
            "        [-0.0265, -0.0106,  0.0474,  ..., -0.0438, -0.0147,  0.0119],\n",
            "        [-0.0158,  0.0478,  0.0209,  ...,  0.0478,  0.0075, -0.0202],\n",
            "        [ 0.0152, -0.0380, -0.0496,  ...,  0.0205, -0.0425,  0.0053]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0011,  0.0469, -0.0360, -0.0410,  0.0011, -0.0457, -0.0022,  0.0019,\n",
            "        -0.0380, -0.0483,  0.0283, -0.0483, -0.0313, -0.0146,  0.0194,  0.0389,\n",
            "        -0.0338, -0.0295, -0.0212, -0.0261,  0.0233,  0.0372, -0.0270, -0.0402,\n",
            "        -0.0078,  0.0198, -0.0100, -0.0387, -0.0383, -0.0383,  0.0491, -0.0258,\n",
            "        -0.0378, -0.0372,  0.0455, -0.0440, -0.0087,  0.0169,  0.0166, -0.0226,\n",
            "        -0.0387, -0.0370,  0.0388,  0.0311, -0.0055, -0.0313,  0.0390, -0.0461,\n",
            "        -0.0447,  0.0229,  0.0075,  0.0022,  0.0310,  0.0006, -0.0429, -0.0046,\n",
            "        -0.0215, -0.0134, -0.0443, -0.0410,  0.0346, -0.0003,  0.0408, -0.0074,\n",
            "         0.0331, -0.0204, -0.0108, -0.0055, -0.0188, -0.0449, -0.0262,  0.0423,\n",
            "         0.0419,  0.0361, -0.0167,  0.0347,  0.0412, -0.0423,  0.0185, -0.0169,\n",
            "         0.0092, -0.0482,  0.0264, -0.0174,  0.0165, -0.0375, -0.0342, -0.0218,\n",
            "        -0.0268,  0.0174,  0.0009, -0.0498,  0.0064, -0.0135,  0.0314,  0.0134,\n",
            "        -0.0441,  0.0168,  0.0087, -0.0083, -0.0214,  0.0363, -0.0397,  0.0407,\n",
            "        -0.0466, -0.0496, -0.0015, -0.0313,  0.0186,  0.0125, -0.0347,  0.0478,\n",
            "        -0.0328, -0.0014, -0.0067, -0.0331,  0.0153, -0.0254,  0.0232,  0.0416],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.0165, -0.0170,  0.0819,  ...,  0.0458,  0.0539, -0.0024],\n",
            "        [-0.0889,  0.0545, -0.0452,  ...,  0.0740,  0.0707,  0.0404],\n",
            "        [-0.0609,  0.0056,  0.0039,  ...,  0.0641,  0.0601,  0.0102],\n",
            "        ...,\n",
            "        [ 0.0666,  0.0760,  0.0902,  ..., -0.0370, -0.0363,  0.0863],\n",
            "        [-0.0187,  0.0143,  0.0549,  ..., -0.0768, -0.0621, -0.0331],\n",
            "        [-0.0005,  0.0490,  0.0288,  ...,  0.0155, -0.0624,  0.0276]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0487, -0.0449, -0.0811,  0.0311, -0.0644,  0.0369, -0.0538, -0.0364,\n",
            "         0.0711,  0.0398, -0.0545,  0.0611,  0.0286,  0.0531,  0.0320, -0.0767,\n",
            "         0.0769,  0.0282, -0.0066, -0.0048, -0.0482, -0.0595, -0.0176,  0.0743,\n",
            "        -0.0197,  0.0317,  0.0218,  0.0495,  0.0253,  0.0087, -0.0481, -0.0357,\n",
            "        -0.0757,  0.0154, -0.0329, -0.0892,  0.0838, -0.0762,  0.0720, -0.0734,\n",
            "         0.0344, -0.0788, -0.0403,  0.0683,  0.0544, -0.0143, -0.0456, -0.0888,\n",
            "        -0.0431,  0.0078,  0.0261,  0.0132, -0.0303, -0.0450, -0.0135, -0.0775,\n",
            "         0.0279,  0.0091,  0.0108, -0.0155, -0.0664, -0.0502, -0.0592,  0.0657,\n",
            "         0.0655, -0.0845,  0.0591, -0.0400,  0.0011,  0.0628,  0.0431, -0.0586,\n",
            "         0.0559,  0.0477, -0.0114, -0.0348, -0.0363, -0.0508, -0.0854,  0.0760,\n",
            "        -0.0532,  0.0593,  0.0411,  0.0813], requires_grad=True), Parameter containing:\n",
            "tensor([[-2.2006e-02,  1.0147e-01, -3.5076e-02,  1.8497e-02, -2.5350e-02,\n",
            "          3.0294e-03, -1.0330e-01, -5.8289e-02,  4.4154e-02,  1.5840e-02,\n",
            "          9.3265e-03,  4.2942e-02,  5.5031e-02,  8.2284e-02, -4.2772e-02,\n",
            "          8.9131e-02, -7.0643e-02,  5.8892e-02, -9.8634e-02, -2.4643e-02,\n",
            "         -8.2519e-02,  1.0477e-01,  1.6766e-02, -9.4692e-02, -3.3392e-02,\n",
            "          2.5402e-02,  4.6356e-02, -7.7587e-02, -1.8238e-02, -7.0040e-02,\n",
            "          9.0353e-02, -6.9299e-02,  6.1778e-02,  9.0104e-02,  2.2358e-02,\n",
            "         -1.0553e-01,  4.7780e-03, -6.6036e-03,  1.8007e-02,  9.8544e-02,\n",
            "          5.1633e-02, -1.0425e-01, -8.2731e-02, -8.4263e-03, -1.0882e-01,\n",
            "         -7.4593e-02,  5.9499e-02, -9.9892e-02, -9.5281e-02, -4.9663e-02,\n",
            "         -3.7632e-02, -5.4615e-02,  2.2555e-03, -1.5093e-02, -9.9331e-02,\n",
            "         -2.6906e-02,  1.3640e-02, -4.8429e-02, -4.7795e-02,  9.8692e-03,\n",
            "         -7.8736e-02, -1.5305e-02,  6.1635e-02,  1.0907e-01,  1.0137e-01,\n",
            "         -6.0903e-02, -2.6800e-02, -2.4808e-02, -5.4026e-02, -1.4787e-02,\n",
            "         -9.3850e-02, -6.7866e-02, -4.2407e-03,  8.0820e-02, -7.0389e-02,\n",
            "         -5.1361e-02, -1.0214e-01,  4.1061e-02, -2.1915e-02, -6.2816e-02,\n",
            "          5.7618e-02,  2.6881e-02, -7.2240e-02,  8.6181e-02],\n",
            "        [-1.0496e-01,  3.9366e-02, -4.0477e-02, -1.0867e-01, -1.2839e-02,\n",
            "          1.7798e-02,  9.5578e-02, -9.2593e-02,  3.3076e-02,  4.3089e-02,\n",
            "          4.3889e-02,  1.0418e-01, -6.8992e-02, -4.2950e-03,  4.7976e-02,\n",
            "         -1.3508e-02,  2.6032e-02, -4.1996e-02, -9.3323e-03,  6.4827e-02,\n",
            "          1.0627e-02,  6.7660e-02,  9.1872e-02,  2.9915e-02, -1.2451e-02,\n",
            "         -4.8411e-02,  5.2172e-02, -1.0469e-01, -8.3243e-02,  1.6556e-02,\n",
            "         -1.4563e-02, -5.0852e-02, -2.2640e-02, -1.0855e-01, -1.0345e-01,\n",
            "          9.7182e-02,  1.7342e-02, -8.1327e-02,  1.0059e-03,  5.1642e-02,\n",
            "          4.4619e-02, -2.5617e-02, -8.5118e-02, -1.5634e-02,  9.3186e-02,\n",
            "          9.6951e-02,  2.7696e-02,  3.6037e-02,  1.1266e-02,  1.6072e-02,\n",
            "          3.7856e-02,  1.4606e-02,  6.5616e-02, -3.5175e-02,  1.0318e-01,\n",
            "          7.6379e-02,  4.8734e-02,  7.3974e-02, -7.1712e-03, -4.9735e-03,\n",
            "         -5.4337e-03,  3.0014e-02,  6.4013e-03, -9.0890e-02,  2.5748e-02,\n",
            "         -4.1086e-02, -3.3691e-02, -1.3796e-02, -6.5857e-02,  4.9499e-02,\n",
            "          1.4196e-02,  2.0298e-02,  8.9610e-02, -9.0517e-02,  7.4186e-02,\n",
            "          9.5925e-02,  4.3076e-02,  5.6592e-02, -4.7076e-02,  4.6761e-02,\n",
            "         -9.2216e-02,  1.9262e-04, -7.4697e-02,  1.4519e-02],\n",
            "        [-7.1474e-02,  4.9846e-02, -4.0556e-03,  5.5956e-02, -9.3773e-02,\n",
            "          1.7755e-02, -2.5570e-03,  4.5561e-02, -4.0874e-03, -4.6314e-02,\n",
            "          1.0497e-01, -7.6635e-02,  1.7937e-02,  4.3499e-02,  6.5078e-02,\n",
            "         -9.4423e-02, -9.4738e-02,  9.1681e-02, -7.6580e-02,  9.5431e-02,\n",
            "          8.6213e-02,  7.5918e-02,  9.9365e-03, -7.3286e-02, -6.4928e-02,\n",
            "          6.7155e-02,  7.5365e-02, -3.2088e-02,  6.7443e-02,  8.8329e-02,\n",
            "         -2.2627e-02,  1.4909e-02, -1.5178e-02,  1.5224e-02,  3.1472e-02,\n",
            "          3.1989e-02,  5.5330e-03, -6.3908e-02,  7.5519e-02, -7.1571e-02,\n",
            "          3.3687e-02, -1.6945e-02,  9.4029e-02, -4.2426e-02,  5.3427e-04,\n",
            "          9.4173e-02, -1.0651e-01, -8.4414e-02, -2.4166e-02,  8.3761e-04,\n",
            "         -1.0733e-01,  6.5450e-02,  5.9650e-02,  2.8680e-03, -3.4112e-03,\n",
            "         -1.0722e-01,  4.3760e-02, -1.0853e-01,  1.0894e-01,  1.0687e-01,\n",
            "          2.2900e-02,  5.1002e-02, -2.8604e-02, -6.3311e-02,  8.6171e-02,\n",
            "          9.0014e-02, -5.4685e-02,  6.4586e-02, -2.2441e-02,  5.3089e-02,\n",
            "          7.6439e-02,  7.9592e-03, -7.1141e-03, -1.6905e-02,  2.0244e-02,\n",
            "         -8.2285e-02,  9.6586e-03, -9.3799e-02,  4.7116e-02,  6.8427e-02,\n",
            "         -1.0358e-01, -9.3211e-02, -8.5008e-02, -1.7172e-02],\n",
            "        [ 9.7070e-02, -9.2396e-03,  1.0246e-02, -1.0464e-02, -8.0661e-02,\n",
            "          8.2605e-02,  1.0177e-01,  3.6562e-02, -6.6457e-02,  2.2336e-02,\n",
            "          1.0359e-01, -7.3045e-03, -1.2415e-02,  3.1815e-02, -3.2542e-02,\n",
            "         -7.0243e-02, -2.4538e-02,  3.0035e-02,  4.8891e-02,  9.7794e-02,\n",
            "          7.7647e-02, -3.6670e-02, -3.2992e-02,  4.3168e-02, -1.7179e-02,\n",
            "          1.1283e-02, -3.4615e-02, -3.0146e-02, -3.5738e-02,  1.0433e-01,\n",
            "          6.2959e-02,  5.2332e-02, -6.8947e-02,  5.6672e-02, -7.5624e-02,\n",
            "          3.6818e-02, -9.5664e-02, -1.0578e-01,  4.1903e-02,  6.5804e-02,\n",
            "          1.6779e-02, -1.0902e-01,  9.2385e-02,  4.3820e-02, -1.7306e-02,\n",
            "          1.5894e-02, -9.6415e-02, -1.7695e-02,  1.2749e-02, -1.0071e-01,\n",
            "          9.3490e-05, -2.6420e-02, -3.2533e-02, -1.0438e-01, -9.1237e-02,\n",
            "         -8.5650e-02, -2.9298e-02, -7.2543e-02, -5.6403e-02, -7.6082e-02,\n",
            "         -1.0564e-01, -8.1647e-02, -4.3336e-02,  8.5978e-02, -2.0916e-02,\n",
            "         -1.0168e-01,  5.8384e-02, -3.8721e-02,  6.5620e-02,  3.6741e-02,\n",
            "         -3.8292e-02, -3.7005e-02,  7.7926e-02, -1.7018e-02,  1.0395e-01,\n",
            "         -3.9358e-02,  4.1302e-02, -8.1776e-02, -4.6649e-02,  5.7242e-02,\n",
            "         -9.0888e-02,  8.0958e-02, -6.2723e-02,  6.6630e-02],\n",
            "        [-7.9925e-02, -6.4683e-02, -4.1232e-02, -1.0768e-01,  1.0102e-01,\n",
            "         -7.1650e-02, -1.0160e-01, -7.4276e-02,  3.7485e-02,  6.2315e-02,\n",
            "          7.7590e-02,  7.2391e-02,  5.4676e-02,  5.1912e-02,  3.3745e-02,\n",
            "          3.2736e-03,  6.7537e-02, -8.0439e-02, -2.5727e-02, -6.9188e-03,\n",
            "          3.3358e-02,  5.6892e-03, -7.5641e-02, -1.0048e-01, -1.7662e-03,\n",
            "         -5.2389e-02, -6.1692e-02, -1.0088e-01,  3.6550e-02,  1.0791e-01,\n",
            "         -6.0967e-02,  3.4761e-02,  5.5601e-02, -7.1220e-02,  3.9347e-02,\n",
            "          1.0598e-01,  6.1133e-02, -7.4962e-02, -2.5539e-02, -1.7231e-02,\n",
            "          4.9127e-02, -4.0631e-02, -1.4727e-02, -4.1886e-02, -2.2829e-02,\n",
            "          8.8213e-02, -1.6395e-02,  3.6107e-02, -7.9160e-02,  1.3958e-02,\n",
            "         -9.9887e-02,  6.5038e-03,  1.8693e-02,  2.4773e-02,  7.6705e-02,\n",
            "         -9.1146e-03,  9.7341e-02, -7.5742e-02, -6.9742e-02,  1.3088e-02,\n",
            "         -2.1952e-02,  3.4701e-02,  9.3404e-02, -9.2916e-02,  4.3223e-02,\n",
            "         -3.5096e-02, -7.6177e-03,  1.0417e-01, -9.9653e-02,  4.3780e-02,\n",
            "          7.6798e-02,  7.0804e-03,  5.0706e-02, -5.2743e-02, -5.5036e-02,\n",
            "         -1.0364e-01,  1.5625e-03, -4.7726e-02,  3.1792e-02, -1.0604e-01,\n",
            "         -9.5448e-02, -6.6422e-02, -2.1898e-02,  4.9174e-02],\n",
            "        [-1.0133e-01,  4.8672e-02, -9.9987e-02,  2.1707e-02,  8.5441e-02,\n",
            "         -1.0451e-01,  2.6181e-02,  1.4508e-03, -4.0940e-02,  5.0813e-02,\n",
            "          5.9781e-02,  2.9468e-02,  3.4110e-02,  3.1370e-03, -4.2492e-02,\n",
            "         -8.7684e-02, -5.8311e-03,  1.1087e-02,  6.3560e-02,  7.8622e-02,\n",
            "          4.0991e-02, -5.8149e-02,  7.1146e-02,  7.6647e-02, -4.7214e-02,\n",
            "         -5.1775e-02,  7.4162e-02, -4.8368e-02,  4.6122e-02,  9.6369e-02,\n",
            "          3.5129e-02,  4.5056e-02, -6.5797e-02,  3.4107e-02, -1.8519e-02,\n",
            "          4.7217e-02,  9.6942e-03, -2.8906e-02, -9.0596e-03,  5.0875e-03,\n",
            "         -7.1142e-02, -6.9425e-03, -7.4112e-02,  8.3888e-02,  6.9242e-02,\n",
            "         -6.1979e-02, -4.5563e-02,  5.3189e-02, -2.3885e-02,  1.9134e-02,\n",
            "         -9.9908e-02, -4.7588e-02, -8.6812e-03,  8.6168e-03, -4.2531e-02,\n",
            "          2.5084e-02, -9.9662e-02, -4.6330e-02, -3.1441e-02, -9.4054e-02,\n",
            "         -1.0523e-01,  2.9990e-03,  8.2847e-02, -5.7304e-02, -8.3236e-02,\n",
            "          3.8152e-02,  2.7130e-02, -4.1102e-02,  5.5556e-02,  3.3747e-02,\n",
            "          7.4676e-03,  3.8600e-02,  4.9726e-02,  2.3288e-02, -7.2072e-02,\n",
            "          7.6956e-02,  7.7735e-02,  9.6840e-02, -7.7792e-02, -3.2093e-02,\n",
            "         -6.8805e-02, -3.3638e-03, -6.9071e-03, -7.8050e-03],\n",
            "        [-3.0995e-02, -7.2751e-02,  3.7838e-02, -5.7291e-02,  6.4966e-02,\n",
            "          4.9803e-02,  8.4835e-02, -8.3867e-03,  1.2376e-02,  5.1275e-02,\n",
            "          9.4846e-02, -1.0736e-02, -7.5781e-02,  1.0036e-01, -3.5798e-02,\n",
            "         -2.0498e-02, -7.5583e-02,  8.5841e-02, -6.9101e-02,  4.4959e-02,\n",
            "          1.0872e-01, -8.8811e-02, -5.5700e-02,  7.6341e-02, -8.0046e-02,\n",
            "          1.8670e-02, -8.9472e-03, -1.0098e-01,  1.6021e-02, -4.7921e-02,\n",
            "          9.3340e-02,  6.5481e-02,  1.9739e-02,  3.4058e-03, -8.4542e-02,\n",
            "         -1.0162e-01, -5.6649e-02,  6.0440e-02, -2.5164e-02, -6.4290e-02,\n",
            "          5.3737e-03,  4.3818e-02, -8.8219e-02, -1.2884e-02,  4.6780e-02,\n",
            "          7.7055e-02, -5.8295e-02, -1.0020e-01, -5.8761e-02,  2.8904e-02,\n",
            "         -9.6866e-03, -9.2258e-02,  5.2036e-02, -4.1137e-02, -6.8743e-02,\n",
            "         -5.0081e-02, -2.1429e-03, -2.4672e-02, -1.6613e-02, -1.0084e-01,\n",
            "         -1.0554e-01,  7.2852e-02,  4.8959e-04,  2.4001e-02,  5.7420e-02,\n",
            "         -2.3427e-02, -3.0891e-02, -2.5682e-02, -5.1067e-02, -9.1708e-02,\n",
            "          8.9442e-02,  5.4559e-03,  5.7717e-02,  8.2039e-02,  5.6660e-02,\n",
            "         -2.6192e-02, -2.8140e-02,  7.8448e-02, -2.7128e-02,  3.3049e-02,\n",
            "          1.6553e-02, -5.3584e-02,  3.4938e-02,  1.5483e-02],\n",
            "        [ 5.2317e-02, -8.1222e-02,  9.3859e-02,  8.2341e-02,  1.0118e-01,\n",
            "          4.3300e-02, -4.2318e-02,  6.8369e-02, -8.7612e-02, -8.0455e-02,\n",
            "         -3.6203e-02,  3.7757e-02,  9.6962e-02,  6.6045e-03, -3.1118e-02,\n",
            "         -3.0616e-02,  5.0935e-02,  8.9553e-02,  8.4855e-02,  9.8025e-02,\n",
            "         -3.8859e-02, -9.0571e-02, -1.4410e-02,  8.9798e-03,  9.4161e-02,\n",
            "          9.9905e-02, -1.5121e-02,  5.8803e-02,  3.1903e-02, -3.2294e-02,\n",
            "          5.5918e-02, -7.8462e-02, -9.7544e-02, -9.9530e-02, -4.6336e-02,\n",
            "          6.3681e-02, -8.8466e-02, -1.7331e-02,  9.8005e-02,  2.8260e-02,\n",
            "          1.0277e-01, -4.5371e-02, -9.9746e-02,  8.2156e-02, -8.4550e-02,\n",
            "          1.0947e-02,  1.0069e-01, -1.0152e-01,  5.9867e-02,  3.3896e-02,\n",
            "          8.2488e-02,  4.3712e-02,  1.7451e-02,  3.7102e-02,  2.5030e-02,\n",
            "         -3.6762e-03,  5.7426e-02, -9.6991e-03,  7.1691e-02,  9.3260e-02,\n",
            "         -4.6872e-02,  9.7810e-03, -5.0726e-02, -7.6277e-02, -9.9123e-02,\n",
            "          7.8526e-02, -6.9151e-03, -1.0315e-01, -7.2479e-02,  8.1777e-02,\n",
            "         -6.2230e-02,  9.4203e-02,  2.2639e-02, -7.4415e-02, -9.3393e-02,\n",
            "          4.7743e-02, -8.7930e-02, -1.0677e-01, -1.0687e-01, -2.4992e-02,\n",
            "         -2.6640e-02,  4.0714e-02,  6.8414e-02, -6.8966e-03],\n",
            "        [ 4.6288e-02, -9.1861e-02, -6.0364e-02,  4.0820e-02,  1.7034e-02,\n",
            "         -3.9406e-02, -8.6327e-02,  9.0467e-02,  5.5092e-02,  1.0341e-01,\n",
            "         -9.5197e-02, -6.7312e-02, -6.7183e-02, -6.5710e-02,  1.8407e-02,\n",
            "         -7.4478e-02, -1.1980e-02,  1.0441e-01,  2.5743e-02,  5.6756e-02,\n",
            "          5.2138e-03, -4.3993e-02,  6.6031e-02, -1.2548e-02, -4.8564e-02,\n",
            "         -4.1081e-02,  7.5754e-02, -4.6759e-02, -6.0664e-02,  2.5975e-03,\n",
            "          3.5099e-02, -9.5915e-02, -3.6420e-02,  9.2587e-02, -9.9039e-02,\n",
            "         -2.8254e-02,  6.2333e-02,  5.9536e-02,  7.6483e-02, -2.3280e-02,\n",
            "          1.0190e-01, -8.4346e-02,  1.9173e-02,  7.5422e-02, -6.4491e-03,\n",
            "          1.0387e-01, -9.5675e-02, -3.4173e-03,  7.8697e-02,  8.7296e-02,\n",
            "         -7.6259e-02, -2.9558e-02, -1.6969e-02,  2.6379e-03,  5.0547e-02,\n",
            "         -7.7954e-02,  1.1965e-02, -3.7087e-02,  1.0551e-01,  3.7009e-02,\n",
            "         -1.8544e-02,  9.4734e-02,  3.2818e-02,  1.0507e-01, -7.5987e-02,\n",
            "         -6.7608e-02, -7.9195e-02, -2.8169e-02,  9.7746e-02, -1.3207e-02,\n",
            "         -2.4157e-02,  5.9746e-02, -5.7750e-02, -1.4290e-02, -2.6073e-02,\n",
            "         -1.0547e-01, -4.9547e-02, -2.9747e-02,  5.3018e-02, -9.8538e-02,\n",
            "          7.6399e-02,  5.6485e-02,  5.4936e-02, -3.7159e-02],\n",
            "        [-2.3374e-02, -1.2683e-02,  5.0688e-02, -6.3096e-02, -5.5926e-02,\n",
            "          7.3723e-02,  9.8458e-02,  2.5744e-02, -3.7762e-02, -7.8155e-02,\n",
            "         -5.4647e-02,  1.4502e-02, -8.9327e-02, -8.9641e-02, -1.2674e-02,\n",
            "         -1.3981e-02, -3.9370e-02, -3.1189e-02,  1.0892e-01, -8.7290e-02,\n",
            "         -1.1310e-03,  1.6948e-03, -5.5906e-02,  7.1466e-02,  1.5047e-02,\n",
            "          4.1842e-02,  8.6729e-02, -5.9331e-02, -1.0582e-01,  7.8663e-02,\n",
            "          1.7754e-03,  5.9327e-02, -5.7061e-02, -5.9109e-02,  1.0641e-02,\n",
            "         -1.0002e-01, -7.4431e-02, -7.4674e-02,  2.7777e-02,  8.6964e-02,\n",
            "          2.0035e-02, -8.1063e-02,  2.9202e-02, -7.3616e-02, -4.9504e-02,\n",
            "         -2.9943e-02, -7.7059e-02,  4.0905e-02, -2.8575e-02,  4.3537e-02,\n",
            "          9.2831e-02, -4.7544e-02,  7.4573e-02, -6.8474e-02, -9.2120e-02,\n",
            "         -5.0287e-02, -2.1493e-02, -5.9865e-02, -4.9505e-02, -8.3346e-02,\n",
            "         -5.4994e-02, -6.8749e-02, -6.6591e-03, -5.7167e-02, -1.8765e-02,\n",
            "          1.1377e-02, -8.0578e-03, -6.4108e-02,  8.5884e-02, -7.3348e-02,\n",
            "          4.7814e-02, -9.3832e-02,  5.4287e-02, -3.2833e-02,  9.2767e-02,\n",
            "          1.6196e-02, -8.5277e-02, -8.3541e-02,  8.5865e-02, -7.2830e-02,\n",
            "          7.7892e-02, -4.7644e-02,  6.8817e-02,  8.4089e-02]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0084, -0.1036,  0.0285, -0.0302, -0.0868, -0.0125, -0.0026, -0.0110,\n",
            "        -0.0163, -0.0160], requires_grad=True)]\n"
          ]
        }
      ],
      "source": [
        "params = list(net.parameters())\n",
        "print(len(params))\n",
        "print(params[0].size())  # conv1's .weight\n",
        "print(params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try a random 32x32 input.\n",
        "Note: expected input size of this net (LeNet) is 32x32. To use this net on\n",
        "the MNIST dataset, please resize the images from the dataset to 32x32.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[ 0.0824, -0.0806, -0.0194, -0.0182, -0.1452, -0.0972, -0.0114,  0.0745,\n",
            "          0.0612, -0.0126]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn(1, 1, 32, 32)\n",
        "out = net(input)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Zero the gradient buffers of all parameters and backprops with random\n",
        "gradients:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "net.zero_grad()\n",
        "out.backward(torch.randn(1, 10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>``torch.nn`` only supports mini-batches. The entire ``torch.nn``\n",
        "    package only supports inputs that are a mini-batch of samples, and not\n",
        "    a single sample.\n",
        "\n",
        "    For example, ``nn.Conv2d`` will take in a 4D Tensor of\n",
        "    ``nSamples x nChannels x Height x Width``.\n",
        "\n",
        "    If you have a single sample, just use ``input.unsqueeze(0)`` to add\n",
        "    a fake batch dimension.</p></div>\n",
        "\n",
        "Before proceeding further, let's recap all the classes you’ve seen so far.\n",
        "\n",
        "**Recap:**\n",
        "  -  ``torch.Tensor`` - A *multi-dimensional array* with support for autograd\n",
        "     operations like ``backward()``. Also *holds the gradient* w.r.t. the\n",
        "     tensor.\n",
        "  -  ``nn.Module`` - Neural network module. *Convenient way of\n",
        "     encapsulating parameters*, with helpers for moving them to GPU,\n",
        "     exporting, loading, etc.\n",
        "  -  ``nn.Parameter`` - A kind of Tensor, that is *automatically\n",
        "     registered as a parameter when assigned as an attribute to a*\n",
        "     ``Module``.\n",
        "  -  ``autograd.Function`` - Implements *forward and backward definitions\n",
        "     of an autograd operation*. Every ``Tensor`` operation creates at\n",
        "     least a single ``Function`` node that connects to functions that\n",
        "     created a ``Tensor`` and *encodes its history*.\n",
        "\n",
        "**At this point, we covered:**\n",
        "  -  Defining a neural network\n",
        "  -  Processing inputs and calling backward\n",
        "\n",
        "**Still Left:**\n",
        "  -  Computing the loss\n",
        "  -  Updating the weights of the network\n",
        "\n",
        "## Loss Function\n",
        "A loss function takes the (output, target) pair of inputs, and computes a\n",
        "value that estimates how far away the output is from the target.\n",
        "\n",
        "There are several different\n",
        "[loss functions](https://pytorch.org/docs/nn.html#loss-functions) under the\n",
        "nn package .\n",
        "A simple loss is: ``nn.MSELoss`` which computes the mean-squared error\n",
        "between the output and the target.\n",
        "\n",
        "For example:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.6570, grad_fn=<MseLossBackward0>)\n"
          ]
        }
      ],
      "source": [
        "output = net(input)\n",
        "target = torch.randn(10)  # a dummy target, for example\n",
        "target = target.view(1, -1)  # make it the same shape as output\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "loss = criterion(output, target)\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, if you follow ``loss`` in the backward direction, using its\n",
        "``.grad_fn`` attribute, you will see a graph of computations that looks\n",
        "like this:\n",
        "\n",
        "::\n",
        "\n",
        "    input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
        "          -> flatten -> linear -> relu -> linear -> relu -> linear\n",
        "          -> MSELoss\n",
        "          -> loss\n",
        "\n",
        "So, when we call ``loss.backward()``, the whole graph is differentiated\n",
        "w.r.t. the neural net parameters, and all Tensors in the graph that have\n",
        "``requires_grad=True`` will have their ``.grad`` Tensor accumulated with the\n",
        "gradient.\n",
        "\n",
        "For illustration, let us follow a few steps backward:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<MseLossBackward0 object at 0x000001F8643D5C30>\n",
            "<AddmmBackward0 object at 0x000001F8643D5A80>\n",
            "<AccumulateGrad object at 0x000001F8643D5C30>\n"
          ]
        }
      ],
      "source": [
        "print(loss.grad_fn)  # MSELoss\n",
        "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
        "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backprop\n",
        "To backpropagate the error all we have to do is to ``loss.backward()``.\n",
        "You need to clear the existing gradients though, else gradients will be\n",
        "accumulated to existing gradients.\n",
        "\n",
        "\n",
        "Now we shall call ``loss.backward()``, and have a look at conv1's bias\n",
        "gradients before and after the backward.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.bias.grad before backward\n",
            "None\n",
            "conv1.bias.grad after backward\n",
            "tensor([ 0.0058,  0.0017,  0.0043,  0.0127,  0.0044, -0.0123])\n"
          ]
        }
      ],
      "source": [
        "net.zero_grad()     # zeroes the gradient buffers of all parameters\n",
        "\n",
        "print('conv1.bias.grad before backward')\n",
        "print(net.conv1.bias.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('conv1.bias.grad after backward')\n",
        "print(net.conv1.bias.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we have seen how to use loss functions.\n",
        "\n",
        "**Read Later:**\n",
        "\n",
        "  The neural network package contains various modules and loss functions\n",
        "  that form the building blocks of deep neural networks. A full list with\n",
        "  documentation is [here](https://pytorch.org/docs/nn).\n",
        "\n",
        "**The only thing left to learn is:**\n",
        "\n",
        "  - Updating the weights of the network\n",
        "\n",
        "## Update the weights\n",
        "The simplest update rule used in practice is the Stochastic Gradient\n",
        "Descent (SGD):\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    weight = weight - learning_rate * gradient\n",
        "\n",
        "We can implement this using simple Python code:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    learning_rate = 0.01\n",
        "    for f in net.parameters():\n",
        "        f.data.sub_(f.grad.data * learning_rate)\n",
        "\n",
        "However, as you use neural networks, you want to use various different\n",
        "update rules such as SGD, Nesterov-SGD, Adam, RMSProp, etc.\n",
        "To enable this, we built a small package: ``torch.optim`` that\n",
        "implements all these methods. Using it is very simple:\n",
        "\n",
        ".. code:: python\n",
        "\n",
        "    import torch.optim as optim\n",
        "\n",
        "    # create your optimizer\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "    # in your training loop:\n",
        "    optimizer.zero_grad()   # zero the gradient buffers\n",
        "    output = net(input)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()    # Does the update\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. Note::\n",
        "\n",
        "      Observe how gradient buffers had to be manually set to zero using\n",
        "      ``optimizer.zero_grad()``. This is because gradients are accumulated\n",
        "      as explained in the `Backprop`_ section.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
